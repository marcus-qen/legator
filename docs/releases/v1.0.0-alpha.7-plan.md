# v1.0.0-alpha.7 — "Fleet Intelligence"

**Theme:** Cross-probe queries — the feature that makes Legator a fleet tool, not just a per-machine chat.

**Current state:** Chat is per-probe only. The LLM sees one probe's inventory and dispatches commands to that single machine. There's no way to ask "which machine has the most disk pressure?" or "compare memory usage across my fleet."

**Goal:** An operator can open a fleet chat, ask questions about the entire fleet, and get answers that span probes. The LLM can dispatch commands to any probe (or multiple probes) based on context.

---

## Deliverables

### P7-1: Fleet Inventory API (medium)

Aggregated fleet inventory endpoint for both API consumers and LLM context building.

**New endpoints:**
- `GET /api/v1/fleet/inventory` — all probes' inventory (hostname, OS, arch, CPUs, RAM, disk, services, packages)
- Query filters: `?tag=linux`, `?status=online`, `?os=ubuntu`
- Response includes per-probe summary + fleet-wide aggregates (total CPUs, total RAM, probe count by OS)

**Implementation:**
- New handler in `server/routes.go`
- Fleet manager method: `InventorySummary(filters) -> FleetInventory`
- Struct: `FleetInventory{Probes []ProbeInventorySummary, Aggregates FleetAggregates}`

### P7-2: Fleet Chat Responder (high)

New LLM responder that operates at fleet scope, not probe scope.

**Key differences from per-probe chat:**
- System prompt includes ALL online probes' inventory summaries
- LLM can target commands to specific probes: `{"command":"df -h /", "probe":"prb-51fd13f7", "reason":"check disk"}`
- LLM can target by tag/hostname: `{"command":"uptime", "target":"linux", "reason":"fleet uptime"}`
- Multi-probe dispatch: sends command to selected probe(s), collects results, summarises
- Conversation history stored at fleet scope (new `fleet` chat session, not per-probe)

**Implementation:**
- `internal/controlplane/llm/fleet_responder.go` — new FleetChatResponder
- New system prompt with fleet context builder
- Multi-probe command dispatch function
- Max 5 command iterations per turn (same as probe chat)
- Tests: fleet context building, multi-probe dispatch, command targeting

### P7-3: Fleet Chat API + WebSocket (medium)

REST + WebSocket endpoints for fleet chat, mirroring per-probe chat pattern.

**New endpoints:**
- `GET /api/v1/fleet/chat` — fleet chat history
- `POST /api/v1/fleet/chat` — send message to fleet chat
- `GET /ws/fleet-chat` — WebSocket for fleet chat
- `GET /fleet/chat` — web page route

**Implementation:**
- Extend chat store with fleet session support (probe_id = "fleet" or empty)
- New handlers wired to FleetChatResponder
- Permission: FleetRead (same as probe chat)

### P7-4: Fleet Chat UI (medium)

Web page for fleet-level conversation.

**Features:**
- Same layout as probe chat (centred conversation, slide-over context)
- Context panel shows fleet summary instead of single probe
- Fleet navigation: link from dashboard, sidebar/header
- Probe cards in context panel (clickable → per-probe chat)

**Implementation:**
- `web/templates/fleet-chat.html` — new template
- Dashboard "Fleet Chat" button
- Reuse CSS from existing chat page

### P7-5: Login Audit Events (low)

Close the alpha.6 gap: OIDC and local logins not captured in audit log.

**Implementation:**
- Emit `auth.login` event on successful login (local + OIDC)
- Emit `auth.login_failed` event on failed login
- Include: user ID, method (local/oidc), IP, timestamp
- Wire through existing audit recorder

---

## Architecture Notes

### Fleet Context Builder
```
buildFleetContext(probes []*ProbeState) string

For each online probe:
  - ID, hostname, OS, arch, CPUs, RAM, disk usage, policy level
  - Top 5 services, package count
  - Last seen timestamp

Fleet summary line:
  - Total probes, online count, total CPUs, total RAM
  - Tag distribution
```

### Command Targeting Protocol
The fleet responder accepts an extended command format:
```json
{"command": "df -h /", "probe": "prb-51fd13f7", "reason": "check disk on principia"}
{"command": "uptime", "target": "all", "reason": "fleet-wide uptime"}
{"command": "free -m", "target": "tag:k8s-host", "reason": "memory on k8s nodes"}
```

If no `probe` or `target` specified, LLM must be asked to clarify.

### Multi-probe Result Format
```
[Results from 2 probes]

principia (prb-51fd13f7):
  exit=0, 4ms
  stdout: ...

castra (prb-63655638):
  exit=0, 3ms
  stdout: ...
```

---

## Execution Plan

1. P7-5 first (quick win, 10 min)
2. P7-1 fleet inventory API (foundation for responder)
3. P7-2 fleet responder (core intelligence)
4. P7-3 fleet chat API + WS (plumbing)
5. P7-4 fleet chat UI (user-facing)

## Success Criteria

- [ ] `POST /api/v1/fleet/chat` with "which machine has more disk space?" returns a meaningful multi-probe answer
- [ ] `GET /api/v1/fleet/inventory` returns aggregated inventory for all online probes
- [ ] Fleet chat UI loads and works end-to-end
- [ ] Login events appear in audit log
- [ ] All existing tests green + new tests for fleet responder
